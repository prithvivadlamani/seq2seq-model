{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7c76ba-f996-4c03-8115-1ff162a1d193",
   "metadata": {},
   "source": [
    "# CS 584 Assignment 4 -- Sequence to Sequence Models\n",
    "\n",
    "#### Name: (Your Name, double click this cell to edit)\n",
    "#### Stevens ID: (Your ID, double click this cell to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3049c644-1868-4884-9092-c386a2b8f796",
   "metadata": {},
   "source": [
    "## In this assignment, you are required to follow the steps below:\n",
    "1. Review the lecture slides.\n",
    "2. Implement the seq2seq (translation) model.\n",
    "\n",
    "**Before you start**\n",
    "- Please read the code very carefully.\n",
    "- Install these packages using the following command.\n",
    "```console\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "- It's better to train the Tensorflow model with GPU and CUDA. If they are not available on your local machine, please consider Google CoLab. You can check `CoLab.md` in this assignments.\n",
    "- You are **NOT** allowed to use other packages unless otherwise specified.\n",
    "- You are **ONLY** allowed to edit the code between `# Start your code here` and `# End` for each block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac7acc6-10d0-45b5-9372-b1f51ea43592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def print_line(*args):\n",
    "    \"\"\" Inline print and go to the begining of line\n",
    "    \"\"\"\n",
    "    args1 = [str(arg) for arg in args]\n",
    "    str_ = ' '.join(args1)\n",
    "    print('\\r' + str_, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f2824-a6f3-4ef3-a50c-197f841b7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# If you are going to use GPU, make sure the GPU in in the output\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c87f0d-f4a4-4250-87ce-9e06c97c5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union, Dict\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02036c6-d232-445f-b04c-6293a7521438",
   "metadata": {},
   "source": [
    "## 1. Data preparation (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f2127-8978-421c-a76b-07c87eab3801",
   "metadata": {},
   "source": [
    "### 1.1 Load and describe data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e87bb-a5f3-46b2-9848-2a2965ea87f1",
   "metadata": {},
   "source": [
    "Here, we use the [iwslt2017](https://huggingface.co/datasets/iwslt2017) dataset. More specifically, this translation task is from French to English: fr-en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9571f-885c-4b16-bf20-39e9431305a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# The load_dataset function is provided by the huggingface datasets\n",
    "# https://huggingface.co/docs/datasets/index\n",
    "\n",
    "\n",
    "dataset_path = os.path.join('a4-data', 'dataset')\n",
    "dataset = load_dataset('iwslt2017', 'iwslt2017-en-fr', cache_dir=dataset_path, ignore_verifications=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e8e6b-a386-4e31-bf2e-3f8dc79bec0b",
   "metadata": {},
   "source": [
    "Let's first print some basic statistics of this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62dbd50-c8ea-4168-9ba5-063e629e1ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)\n",
    "print(len(dataset['train']['translation']), len(dataset['validation']['translation']), len(dataset['test']['translation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855139af-31ba-4fdb-9f48-050d1e391c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['train']['translation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c46a0-62b1-4d06-895c-7d08a2f39e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "# The tokenizer is provided by the huggingface tokenizers\n",
    "# https://huggingface.co/docs/tokenizers/index\n",
    "# Here, I already pretrained a BPE tokenizer and you can simply load the json\n",
    "# The token numbers of both English and French are 10,000\n",
    "# All tokens should be lower-case.\n",
    "\n",
    "\n",
    "en_tokenizer = Tokenizer.from_file('a4-data/en_tokenizer.json')\n",
    "fr_tokenizer = Tokenizer.from_file('a4-data/fr_tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f7703-8836-4cfb-80ff-4e87f7dfa1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = en_tokenizer.encode(\"i like sports.\")\n",
    "print(encoding.ids)\n",
    "print(encoding.tokens)\n",
    "# >>> [0, 122, 279, 4987, 17, 1] \n",
    "# >>> ['<s>', 'Ġi', 'Ġlike', 'Ġsports', '.', '</s>']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8523cc-08c4-451c-b7a8-76322c543e6e",
   "metadata": {},
   "source": [
    "Extract English and French sentences for training, validation, and test sets.\n",
    "\n",
    "Note: Every sentence is lower-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5359d-1993-4f1f-ac6b-6db3911713ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_sentences, train_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['train']['translation']])\n",
    "valid_en_sentences, valid_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['validation']['translation']])\n",
    "test_en_sentences, test_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['test']['translation']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530a74f-e2c7-493d-8fa0-ce8c925f973d",
   "metadata": {},
   "source": [
    "### 1.2 Encode data (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e2d57-8dc5-4f41-988c-1b87b4bd42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(tokenizer: 'Tokenizer', sentences: List[str]) -> List[List[int]]:\n",
    "    \"\"\" Encode the sentences with the pretrained tokenizer.\n",
    "        You can directly call `tokenizer.encode()` to encode the sentences.\n",
    "        It will automatically add the <s> and </s> token.\n",
    "        \n",
    "        Note: Please be carefull with the return value of the encode function.\n",
    "    \n",
    "    Args:\n",
    "        tokenizer: A pretrained en/fr tokenizer\n",
    "        sentences: A list of strings\n",
    "    Return:\n",
    "        sent_token_ids: A list of token ids\n",
    "    \"\"\"\n",
    "    sent_token_ids = []\n",
    "    n = len(sentences)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if i % 100 == 0 or i == n - 1:\n",
    "            print_line('Encoding with Tokenizer:', (i + 1), '/', n)\n",
    "        # Start your code here\n",
    "\n",
    "        # End\n",
    "    print_line('\\n')\n",
    "    return sent_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19675167-bc6d-44f0-920e-284acddc7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('en')\n",
    "train_en = encode(en_tokenizer, train_en_sentences)\n",
    "valid_en = encode(en_tokenizer, valid_en_sentences)\n",
    "test_en = encode(en_tokenizer, test_en_sentences)\n",
    "print('fr')\n",
    "train_fr = encode(fr_tokenizer, train_fr_sentences)\n",
    "valid_fr = encode(fr_tokenizer, valid_fr_sentences)\n",
    "test_fr = encode(fr_tokenizer, test_fr_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b0986e-8851-4e12-aa30-d683a1459791",
   "metadata": {},
   "source": [
    "Check your implementation with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53552f30-349e-4204-86f5-78ee42cfe78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['train']['translation'][0])\n",
    "print(train_en[0], train_fr[0])\n",
    "print(en_tokenizer.decode(train_en[0]), fr_tokenizer.decode(train_fr[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82322d84-66f5-4d87-b6cd-41b996e7a0c5",
   "metadata": {},
   "source": [
    "## 2. Sequence to sequence model (40 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a10839-398f-421c-aac3-d189d61c2982",
   "metadata": {},
   "source": [
    "### 2.1 Encoder (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0cf2c-7a93-4f93-af76-8e702e35929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, GRU, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self, vocab_size: int, embedding_size: int, units: int):\n",
    "        \"\"\" The encoder model for the src sentences.\n",
    "            It contains an embedding part and a GRU part.\n",
    "        \n",
    "        Args:\n",
    "            vocab_size: The src vocabulary size\n",
    "            embedding_size: The embedding size for the embedding layer\n",
    "            units: Number of hidden units in the RNN (GRU) layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Start your code here\n",
    "        # Note: Please know what the decoder needs from encoder. This determines the parameters of the GRU layer\n",
    "\n",
    "        # End\n",
    "\n",
    "    def call(self, src_ids, src_mask):\n",
    "        \"\"\" Encoder forward\n",
    "        Args:\n",
    "            src_ids: Tensor, (batch_size x max_len), the token ids of input sentences in a batch\n",
    "            src_mask: Tensor, (batch_size x max_len), the mask of the src input. True value in the mask means this timestep is valid, otherwise this timestep is ignored\n",
    "        Returns:\n",
    "            enc_output: Tensor, (batch_size x max_len x units), the output of GRU for all timesteps\n",
    "            final_state: Tensor, (batch_size x units), the state of the final valid timestep\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        # Step 1. Retrieve embedding\n",
    "        #      2. GRU\n",
    "        # Please refer to the calling arguments of GRU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU#call-arguments\n",
    "\n",
    "        # End\n",
    "        return enc_outputs, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da95576b-60df-4537-b696-f02bb84507c8",
   "metadata": {},
   "source": [
    "### 2.2 Decoder (15 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4e882-14d4-4ae5-93a8-58405dd58e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, vocab_size: int, embedding_size: int, units: int, dropout_rate: float):\n",
    "        \"\"\" The decoder model for the tgt sentences.\n",
    "            It contains an embedding part, a GRU part, a dropout part, and a classifier part.\n",
    "            \n",
    "        Args:\n",
    "            vocab_size: The tgt vocabulary size\n",
    "            embedding_size: The embedding size for the embedding layer\n",
    "            units: Number of hidden units in the RNN (GRU) layer\n",
    "            dropout_rate: The classifier has a (units x vocab_size) weight. This is a large weight matrix. We apply a dropout layer to avoid overfitting.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Start your code here\n",
    "        # Note: 1. Please correctly set the parameter of GRU\n",
    "        #       2. No softmax here because we will need the sequence to sequence loss later\n",
    "\n",
    "        # End\n",
    "\n",
    "    def call(self, tgt_ids, initial_state, tgt_mask):\n",
    "        \"\"\" Decoder forward.\n",
    "            It is called by decoder(tgt_ids=..., initial_state=..., tgt_mask=...)\n",
    "\n",
    "        Args:\n",
    "            tgt_ids: Tensor, (batch_size x max_len), the token ids of input sentences in a batch\n",
    "            initial_state: Tensor, (batch_size x units), the state of the final valid timestep from the encoder\n",
    "            tgt_mask: Tensor, (batch_size x max_len), the mask of the tgt input. True value in the mask means this timestep is valid, otherwise this timestep is ignored\n",
    "        Return:\n",
    "            dec_outputs: Tensor, (batch_size x max_len x vocab_size), the output of GRU for all timesteps\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        # Step 1. Retrieve embedding\n",
    "        #      2. GRU\n",
    "        #      3. Apply dropout to the GRU output\n",
    "        #      4. Classifier\n",
    "        # Note: Please refer to the calling arguments of GRU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU#call-arguments\n",
    "\n",
    "        # End\n",
    "        return dec_outputs\n",
    "    \n",
    "    def predict(self, tgt_ids, initial_state):\n",
    "        \"\"\" Decoder prediction.\n",
    "            This is a step in recursive prediction. We use the previous prediction and state to predict current token.\n",
    "            Note that we only need to use the gru_cell instead of GRU becasue we only need to calculate one timestep.\n",
    "            \n",
    "        Args:\n",
    "            tgt_ids: Tensor, (batch_size, ) -> (1, ), the token id of the current timestep in the current sentence.\n",
    "            initial_state: Tensor, (batch_size x units) -> (1 x units), the state of the final valid timestep from the encoder or the previous hidden state in prediction.\n",
    "        Return:\n",
    "            dec_outputs: Tensor, (batch_size x vocab_size) -> (1 x vocab_size), the output of GRU for this timestep.\n",
    "            state: Tensor, (batch_size x units) -> (1 x units), the state of this timestep.\n",
    "        \"\"\"\n",
    "        gru_cell = self.gru.cell\n",
    "        # Start your code here\n",
    "        # Step 1. Retrieve embedding\n",
    "        #      2. GRU Cell, see https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell#call-arguments\n",
    "        #      3. Classifier (No dropout)\n",
    "\n",
    "        # End\n",
    "        return dec_outputs, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1720c69-2fd3-4310-b850-9ce9036bfe23",
   "metadata": {},
   "source": [
    "### 2.3 Seq2seq (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69663d6-bcc9-439e-82fe-a366c71286ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(Model):\n",
    "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, embedding_size: int, units: int, dropout_rate: float):\n",
    "        \"\"\" The sequence to sequence model.\n",
    "            It contains an encoder and a decoder.\n",
    "            \n",
    "        Args:\n",
    "            src_vocab_size: The src vocabulary size\n",
    "            tgt_vocab_size: The tgt vocabulary size\n",
    "            embedding_size: The embedding size for the embedding layer\n",
    "            units: Number of hidden units in the RNN (GRU) layer\n",
    "            dropout_rate: The dropout rate used in the decoder.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Start your code here\n",
    "\n",
    "        # End\n",
    "\n",
    "    def call(self, src_ids, src_seq_lens, tgt_ids, tgt_seq_lens):\n",
    "        \"\"\" Seq2seq forward (for the loss calculation in training/validation only).\n",
    "            It is called by model(src_ids=..., src_seq_lens=..., tgt_ids=..., tgt_seq_lens=)\n",
    "            Note: In prediction, we will also need to set `training=False`.\n",
    "\n",
    "        Args:\n",
    "            src_ids: Tensor, (batch_size x max_len), the token ids of src sentences in a batch\n",
    "            src_seq_lens: Tensor, (batch_size, ), the length of src sentences in a batch\n",
    "            tgt_ids: Tensor, (batch_size x max_len), the token ids of tgt sentences in a batch\n",
    "            tgt_seq_lens: Tensor, (batch_size, ), the length of src sentences in a batch\n",
    "        Returns:\n",
    "            dec_outputs: Tensor, (batch_size x max_len x units), the decoder predictions\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        # Step 1. build mask for src and tgt\n",
    "        #      2. encoder forward\n",
    "        #      3. decoder forward\n",
    "\n",
    "        # End\n",
    "        return dec_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a240b136-ca49-4fc8-ab34-5bc2516cadad",
   "metadata": {},
   "source": [
    "### 2.4 Seq2seq loss (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fac669-188c-4813-9734-ad5d44d406bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.seq2seq import sequence_loss\n",
    "\n",
    "\n",
    "def seq2seq_loss(logits, target, seq_lens):\n",
    "    \"\"\" Calculate the sequence to sequence loss using the sequence_loss from tensorflow\n",
    "    \n",
    "    Args:\n",
    "        logits: Tensor (batch_size x max_seq_len x vocab_size). The output of the RNN model.\n",
    "        target: Tensor (batch_size x max_seq_len). The groud-truth of words.\n",
    "        seq_lens: Tensor (batch_size, ). The real sequence length before padding.\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    # Start your code here\n",
    "    # 1. make a sequence mask (batch_size x max_seq_len) using tf.sequence_mask. This is to build a mask with 1 and 0.\n",
    "    #    Entry with 1 is the valid time step without padding. Entry with 0 is the time step with padding. We need to exclude this time step.\n",
    "    # 2. calculate the loss with sequence_loss. Carefully read the documentation of each parameter\n",
    "\n",
    "    # End\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032d2fb-827f-4132-b128-70babd974f08",
   "metadata": {},
   "source": [
    "## 3. Training (50 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddf45c-adb4-449d-9a5a-052512e5ff97",
   "metadata": {},
   "source": [
    "### 3.1 Pad batch (15 Points)\n",
    "\n",
    "`pad_src_batch`: 5 Points\n",
    "`pad_tgt_batch`: 10 Points\n",
    "\n",
    "Pad the batch to the equal length and make tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d23097-f74d-49cf-8c61-89c60d4b8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_src_batch(src_batch: List[List[int]], src_seq_lens: List[int], pad_val: int):\n",
    "    \"\"\" Pad the batch for src sentences.\n",
    "        Note: Do not use append/extend that can modify the input inplace.\n",
    "    \n",
    "    Args:\n",
    "        src_batch: A list of src token ids\n",
    "        src_seq_lens: A list of src lens\n",
    "        pad_val: The padding value\n",
    "        \n",
    "    Returns:\n",
    "        src_batch: Tensor, (batch_size x max_len)\n",
    "        src_seq_lens_batch: Tensor, (batch_size, )\n",
    "    \"\"\"\n",
    "    max_src_len = max(src_seq_lens)\n",
    "    # Start your code here\n",
    "    # Please refer to tf.convert_to_tensor. The dtype should be tf.int64\n",
    "    # Padding\n",
    "\n",
    "    # Convert to tensor\n",
    "\n",
    "    # End\n",
    "    return src_batch, src_seq_lens_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64baa751-3c5d-49e1-a80b-2efdbcb94bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tgt_batch(tgt_batch: List[List[int]], tgt_seq_lens: List[int], pad_val: int):\n",
    "    \"\"\" Pad the batch for tgt sentences.\n",
    "        Note: 1. Do not use append/extend that can modify the input inplace.\n",
    "              2. We need to build the x (feature) and y (label) for tgt sentences.\n",
    "                 Please understand what the feature and label are in translation.\n",
    "    \n",
    "    Args:\n",
    "        tgt_batch: A list of src token ids\n",
    "        tgt_seq_lens: A list of src lens\n",
    "        pad_val: The padding value\n",
    "        \n",
    "    Returns:\n",
    "        tgt_x_batch: Tensor, (batch_size x max_len)\n",
    "        tgt_y_batch: Tensor, (batch_size x max_len)\n",
    "        src_seq_lens_batch: Tensor, (batch_size, )\n",
    "    \"\"\"\n",
    "    tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch = [], [], []\n",
    "    for sent, seq_len in zip(tgt_batch, tgt_seq_lens):\n",
    "        # Start your code here\n",
    "        # Append x, y, and seq_len\n",
    "\n",
    "        # End\n",
    "\n",
    "    max_tgt_len = max(tgt_seq_lens_batch)\n",
    "    # Start your code here\n",
    "    # Please refer to tf.convert_to_tensor. The dtype should be tf.int64\n",
    "    # Padding\n",
    "\n",
    "    # Convert to tensor\n",
    "\n",
    "    # End\n",
    "    return tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ad89c-7f26-4bb4-a73b-0a19e7fa77c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch(src_batch: List[List[int]], src_seq_lens: List[int], tgt_batch: List[List[int]], tgt_seq_lens: List[int], pad_val: int):\n",
    "    src_batch, src_seq_lens_batch = pad_src_batch(src_batch, src_seq_lens, pad_val)\n",
    "    tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch = pad_tgt_batch(tgt_batch, tgt_seq_lens, pad_val)\n",
    "    return src_batch, src_seq_lens_batch, tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6b26b-fac1-4bf1-a5b1-ae64b9ebbab5",
   "metadata": {},
   "source": [
    "### 3.2 Batch Index Sampler (10 Points)\n",
    "\n",
    "Create a index sampler to sample data index for each batch.\n",
    "\n",
    "This is to make the sentences in each batch have similar lengths to speed up training.\n",
    "\n",
    "Example:\n",
    "```\n",
    "Assume the sentence lengths are: [5, 2, 3, 6, 2, 3, 6] and batch_size is 2.\n",
    "We can make the indices in the batches as follows:\n",
    "[1, 4] of length 2\n",
    "[2, 5] of length 3\n",
    "[0, 3] of lengths 5 and 6\n",
    "[6] of length 6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3f5d5e-3429-4d25-a020-227de440d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqLenBatchSampler:\n",
    "    def __init__(self, seq_lens: List[int], batch_size: int, seed: int = 6666):\n",
    "        \"\"\" The index sampler.\n",
    "            It can be used with iteration:\n",
    "            ```\n",
    "            n_batch = len(sampler)\n",
    "            for indices in sampler:\n",
    "                ...\n",
    "            ```\n",
    "            \n",
    "            Args:\n",
    "                seq_lens: A list training sequence lengths (src)\n",
    "                batch_size: .\n",
    "                seed: .\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.seq_lens = seq_lens\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = self._make_batch_index()\n",
    "\n",
    "        self.n_batch = len(self.batches)\n",
    "        self.counter = -1\n",
    "        \n",
    "    def _make_batch_index(self) -> List[List[int]]:\n",
    "        \"\"\" Build the indexes in each batch.\n",
    "\n",
    "            Return:\n",
    "                batches: A list of indices batch, e.g., [[0, 2, 8], [3, 6, 4], [5, 1, 7], ...]\n",
    "        \"\"\"\n",
    "        n = len(self.seq_lens)\n",
    "        n_batch = int(np.ceil(n / self.batch_size))\n",
    "        batches = []\n",
    "        # Start your code here\n",
    "        # Step 1. Use np.argsort to get all indices with sorted length\n",
    "        #      2. Split the indices into batches using a for loop: `for i in range(n_batch):`\n",
    "\n",
    "        # End\n",
    "        return batches\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batch\n",
    "    \n",
    "    def __item__(self, index):\n",
    "        return self.batches[index]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        np.random.shuffle(self.batches)\n",
    "        self.counter = -1\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        self.counter += 1\n",
    "        if self.counter < self.n_batch:\n",
    "            return self.batches[self.counter]\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43762b66-8820-4f21-9bf2-d59a82ae494f",
   "metadata": {},
   "source": [
    "### 3.3 Running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25553751-af99-4ea1-9097-31bc0ba11b25",
   "metadata": {},
   "source": [
    "Generate the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b46b6e-6dde-4e49-9833-21b887faba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6666)\n",
    "train_seq_lens_en = [len(en_sent) for en_sent in train_en]\n",
    "train_seq_lens_fr = [len(fr_sent) for fr_sent in train_fr]\n",
    "valid_seq_lens_en = [len(en_sent) for en_sent in valid_en]\n",
    "valid_seq_lens_fr = [len(fr_sent) for fr_sent in valid_fr]\n",
    "test_seq_lens_en = [len(en_sent) for en_sent in test_en]\n",
    "test_seq_lens_fr = [len(fr_sent) for fr_sent in test_fr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161d2df-c491-49a3-9d08-beb4b6b6f882",
   "metadata": {},
   "source": [
    "Create np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e974ea-136e-4111-b968-ca78d4c6dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = np.array(train_en, dtype=object)\n",
    "train_seq_lens_en = np.array(train_seq_lens_en)\n",
    "train_fr = np.array(train_fr, dtype=object)\n",
    "train_seq_lens_fr = np.array(train_seq_lens_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63940225-535c-4463-8849-ba34f617be72",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffb6b7-2704-422a-9a87-ee55d27fccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "seed = 6666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a4641-950e-4edf-ac4a-68827a35cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(fr_tokenizer.get_vocab())\n",
    "tgt_vocab_size = len(en_tokenizer.get_vocab())\n",
    "hidden_units = 256\n",
    "embedding_dim = 128\n",
    "dropout_rate = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6a58a-22f2-4c82-8f1e-166fcf79698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2seq(src_vocab_size, tgt_vocab_size, embedding_dim, hidden_units, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a06051-90ff-49ee-8991-014bf0f9d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 15\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640af444-ef86-4ec3-861b-1c543a94a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "train_batch_sampler = SeqLenBatchSampler(train_seq_lens_fr, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f91312-ce07-4164-802e-c6379fc73e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_samples = len(train_fr)\n",
    "n_valid_batch = int(np.ceil(len(valid_fr) / batch_size))\n",
    "pad_token_id = fr_tokenizer.token_to_id('<pad>')\n",
    "train_losses, valid_losses = [], []\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_idx, data_index in enumerate(train_batch_sampler):\n",
    "        src_batch, src_seq_lens = train_fr[data_index], train_seq_lens_fr[data_index]\n",
    "        tgt_batch, tgt_seq_lens = train_en[data_index], train_seq_lens_en[data_index]\n",
    "        real_batch_size = len(src_batch)\n",
    "        (src_batch, src_seq_lens_batch,\n",
    "         tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch) = pad_batch(src_batch, src_seq_lens,\n",
    "                                                                   tgt_batch, tgt_seq_lens,\n",
    "                                                                   pad_val=pad_token_id)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = model(src_batch, src_seq_lens_batch, tgt_x_batch, tgt_seq_lens_batch)\n",
    "            loss = seq2seq_loss(output, tgt_y_batch, tgt_seq_lens_batch)\n",
    "\n",
    "        print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {len(train_batch_sampler)} - loss: {loss:.4f}')\n",
    "\n",
    "        trainable_vars = model.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        epoch_loss += loss * real_batch_size\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    for batch_idx in range(n_valid_batch):\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        src_batch, src_seq_lens = valid_fr[start:end], valid_seq_lens_fr[start:end]\n",
    "        tgt_batch, tgt_seq_lens = valid_en[start:end], valid_seq_lens_en[start:end]\n",
    "        real_batch_size = len(src_batch)\n",
    "        (src_batch, src_seq_lens_batch,\n",
    "         tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch) = pad_batch(src_batch, src_seq_lens,\n",
    "                                                                   tgt_batch, tgt_seq_lens,\n",
    "                                                                   pad_val=pad_token_id)\n",
    "        output = model(src_batch, src_seq_lens_batch, tgt_x_batch, tgt_seq_lens_batch, training=False)\n",
    "        loss = seq2seq_loss(output, tgt_y_batch, tgt_seq_lens_batch)\n",
    "\n",
    "        if batch_idx % 1 == 0 or batch_idx == len(valid_en) - 1:\n",
    "            print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {n_valid_batch} - loss: {loss:.4f}')\n",
    "\n",
    "        valid_loss += loss * real_batch_size\n",
    "    train_epoch_loss = epoch_loss / n_training_samples\n",
    "    valid_epoch_loss = valid_loss / len(valid_en)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    valid_losses.append(valid_epoch_loss)\n",
    "    print(f'\\rEpoch {epoch + 1} / {num_epoch} - Step {len(train_batch_sampler)} / {len(train_batch_sampler)} - train loss: {train_epoch_loss:.4f} - valid loss: {valid_epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767daac-7049-406e-a8ca-65d6ebeac90c",
   "metadata": {},
   "source": [
    "If you implement everything correctly, the valid loss will be around 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff797bf0-b861-4c27-b64a-b470c1aaff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e55e2f-039f-44c2-880a-732300b252c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "x = np.arange(1, len(train_losses) + 1)\n",
    "plt.plot(x, train_losses, label='Train loss')\n",
    "plt.plot(x, valid_losses, label='Valid loss')\n",
    "plt.legend()\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48431b3c-a182-478e-a25d-011cb7680a1d",
   "metadata": {},
   "source": [
    "### 3.4 Translate French to English (15 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd07cb-43d1-40d4-994e-a6ae2b7d5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token_id = en_tokenizer.token_to_id('<s>')\n",
    "eos_token_id = en_tokenizer.token_to_id('</s>')\n",
    "max_pred_len = 200\n",
    "def translate(encoder: 'Encoder', decoder: 'Decoder', fr_sentences: List[List[int]]):\n",
    "    \"\"\" Translate the src (French) sentences to English sentences.\n",
    "        This is a recursive translation.\n",
    "        \n",
    "    Args:\n",
    "        encoder: The encoder part in seq2seq\n",
    "        decoder: The decoder part in seq2seq\n",
    "        fr_sentences: The src token ids of all sentences\n",
    "    Returns:\n",
    "        pred_sentences: The predicted string sentences\n",
    "    \"\"\"\n",
    "    n = len(fr_sentences)\n",
    "    pred_sentences = []\n",
    "    for i, src_ids in enumerate(fr_sentences):\n",
    "        print_line(f'{i + 1} / {n}')\n",
    "        # Shape of src_ids: (1 x seq_len)\n",
    "        src_ids = tf.expand_dims(tf.convert_to_tensor(src_ids, dtype=tf.int64), axis=0)\n",
    "        # pred is the prediction token ids. It starts with <s>\n",
    "        pred = [sos_token_id]\n",
    "        # Start your code here\n",
    "        # Step 1. Calculate the encoder outputs and hidden states (similar to seq2seq2 model)\n",
    "        # Step 2. Run a while loop when the last token in pred is not eos_token_id and the length of pred is less than max_pred_len\n",
    "        # Step 3.     In the while loop, build the input (cur_token) of decoder: the last token of pred. Shape (batch_size, ) -> (1, )\n",
    "        #             For example, if the current pred is [1, 50, 21, 8], the cur_token is [8]\n",
    "        # Step 4.     In the while loop, use decoder.predict to get the decoder output\n",
    "        # Step 5.     In the while loop, find the index with the maximum value. Then you can call tf.squeeze and numpy() to get the index\n",
    "        # Step 6.     In the while loop, append the predicted token to pred\n",
    "        # Step 7. Use en_tokenizer to decode the id to strings: pred_sentence\n",
    "\n",
    "        # End\n",
    "        pred_sentences.append(pred_sentence)\n",
    "    print_line('\\n')\n",
    "    return pred_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce651b96-8127-4d76-a2e3-6c643d5cdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = translate(model.encoder, model.decoder, fr_sentences=test_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07764c0e-ef49-4475-8dd0-057d1fd21be1",
   "metadata": {},
   "source": [
    "### 3.5 Demonstrate 10 translation examples (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a7812d-bd93-4eeb-8292-a7dca60beed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6666)\n",
    "sample_num = 10\n",
    "# Start your code here\n",
    "# Use np.random.choice to sample 10 sentence indices. Remember to set correct replace\n",
    "# Print format:\n",
    "# 1.\n",
    "# French: ...\n",
    "# True English: ...\n",
    "# Translated English: ...\n",
    "# ------------------\n",
    "\n",
    "# End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a77aeb-c930-4553-9d4a-d5f72622af2c",
   "metadata": {},
   "source": [
    "### 3.6 Compute the bleu score (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d4b57-3015-427b-a6fd-d69139c29498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "sacrebleu = evaluate.load('sacrebleu', cache_dir=dataset_path)\n",
    "# Start your code here\n",
    "# see https://huggingface.co/spaces/evaluate-metric/sacrebleu\n",
    "# Note: please understand the format and meaning of references.\n",
    "\n",
    "# End\n",
    "score = results['score']\n",
    "print(round(score, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d18a1-2fc3-4ea2-89be-6db4326a2d8f",
   "metadata": {},
   "source": [
    "If you implement everything correctly, the BLEU score will be around 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8074e54-0b0d-45b7-87f9-2be1dc70532f",
   "metadata": {},
   "source": [
    "## Conclusion (5 Points)\n",
    "\n",
    "Including but not limited to: translation example analysis (case study), bleu score analysis, model structure / parameter analysis, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbf908-27e5-4cba-a2d9-5ac308113c15",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
